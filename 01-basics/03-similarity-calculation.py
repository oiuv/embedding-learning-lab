#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬3è¯¾ï¼šè®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
========================

æœ¬è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•è®¡ç®—æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
2. å®ç°ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
3. æ¯”è¾ƒä¸åŒæ–‡æœ¬çš„ç›¸ä¼¼æ€§
4. ç†è§£ç›¸ä¼¼åº¦é˜ˆå€¼çš„æ„ä¹‰

"""

import os
import sys
import numpy as np
from typing import List, Tuple, Dict
from openai import OpenAI

class SimilarityCalculator:
    """æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—å™¨"""
    
    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–è®¡ç®—å™¨"""
        try:
            self.client = OpenAI(
                api_key=api_key or os.getenv("DASHSCOPE_API_KEY"),
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
            self.model = "text-embedding-v4"
            self.dimensions = 1024
            print("âœ… ç›¸ä¼¼åº¦è®¡ç®—å™¨åˆå§‹åŒ–æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            sys.exit(1)
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬åµŒå…¥å‘é‡"""
        try:
            response = self.client.embeddings.create(
                model=self.model,
                input=[text],
                dimensions=self.dimensions,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ è·å–åµŒå…¥å¤±è´¥: {e}")
            return []
    
    def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–æ–‡æœ¬åµŒå…¥"""
        try:
            response = self.client.embeddings.create(
                model=self.model,
                input=texts,
                dimensions=self.dimensions,
                encoding_format="float"
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            print(f"âŒ æ‰¹é‡è·å–å¤±è´¥: {e}")
            return []
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        v1 = np.array(vec1)
        v2 = np.array(vec2)
        
        # è®¡ç®—ç‚¹ç§¯
        dot_product = np.dot(v1, v2)
        
        # è®¡ç®—èŒƒæ•°
        norm1 = np.linalg.norm(v1)
        norm2 = np.linalg.norm(v2)
        
        # é¿å…é™¤ä»¥é›¶
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = dot_product / (norm1 * norm2)
        return max(-1.0, min(1.0, similarity))  # ç¡®ä¿èŒƒå›´åœ¨[-1, 1]
    
    def euclidean_distance(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—æ¬§æ°è·ç¦»"""
        return np.linalg.norm(np.array(vec1) - np.array(vec2))
    
    def manhattan_distance(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—æ›¼å“ˆé¡¿è·ç¦»"""
        return np.sum(np.abs(np.array(vec1) - np.array(vec2)))
    
    def demonstrate_similarity_calculation(self):
        """æ¼”ç¤ºç›¸ä¼¼åº¦è®¡ç®—"""
        print("ğŸ¯ ç¬¬1éƒ¨åˆ†ï¼šåŸºç¡€ç›¸ä¼¼åº¦è®¡ç®—")
        print("=" * 50)
        
        # ç¤ºä¾‹æ–‡æœ¬
        text1 = "æœºå™¨å­¦ä¹ "
        text2 = "æ·±åº¦å­¦ä¹ "
        text3 = "è‹¹æœ"
        
        # è·å–åµŒå…¥
        print("ğŸ“Š è·å–æ–‡æœ¬åµŒå…¥...")
        emb1 = self.get_embedding(text1)
        emb2 = self.get_embedding(text2)
        emb3 = self.get_embedding(text3)
        
        if not all([emb1, emb2, emb3]):
            print("âŒ è·å–åµŒå…¥å¤±è´¥")
            return
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        sim_12 = self.cosine_similarity(emb1, emb2)
        sim_13 = self.cosine_similarity(emb1, emb3)
        sim_23 = self.cosine_similarity(emb2, emb3)
        
        print(f"\nğŸ“ˆ ç›¸ä¼¼åº¦ç»“æœ:")
        print(f"   '{text1}' vs '{text2}': {sim_12:.4f}")
        print(f"   '{text1}' vs '{text3}': {sim_13:.4f}")
        print(f"   '{text2}' vs '{text3}': {sim_23:.4f}")
        
        # è§£é‡Šç»“æœ
        print(f"\nğŸ“ ç»“æœåˆ†æ:")
        print(f"   â€¢ ä½™å¼¦ç›¸ä¼¼åº¦èŒƒå›´: [-1, 1]")
        print(f"   â€¢ 1.0: å®Œå…¨ç›¸åŒ")
        print(f"   â€¢ 0.0: å®Œå…¨ä¸ç›¸å…³")
        print(f"   â€¢ -1.0: å®Œå…¨ç›¸å")
    
    def compare_different_similarity_methods(self):
        """æ¯”è¾ƒä¸åŒçš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•"""
        print("\nğŸ¯ ç¬¬2éƒ¨åˆ†ï¼šä¸åŒç›¸ä¼¼åº¦æ–¹æ³•æ¯”è¾ƒ")
        print("=" * 50)
        
        # ç¤ºä¾‹æ–‡æœ¬å¯¹
        text_pairs = [
            ("è‹¹æœ", "é¦™è•‰"),
            ("æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ "),
            ("æ±½è½¦", "é£æœº"),
            ("é«˜å…´", "å¿«ä¹")
        ]
        
        # è·å–æ‰€æœ‰æ–‡æœ¬çš„åµŒå…¥
        all_texts = list(set([text for pair in text_pairs for text in pair]))
        embeddings = {}
        
        for text in all_texts:
            embeddings[text] = self.get_embedding(text)
        
        # è®¡ç®—ä¸åŒæ–¹æ³•çš„ç›¸ä¼¼åº¦
        print("\nğŸ“Š ç›¸ä¼¼åº¦æ¯”è¾ƒ:")
        print(f"{'æ–‡æœ¬å¯¹':<20} {'ä½™å¼¦':<10} {'æ¬§æ°è·ç¦»':<10} {'æ›¼å“ˆé¡¿':<10}")
        print("-" * 50)
        
        for text1, text2 in text_pairs:
            emb1 = embeddings[text1]
            emb2 = embeddings[text2]
            
            cosine = self.cosine_similarity(emb1, emb2)
            euclidean = self.euclidean_distance(emb1, emb2)
            manhattan = self.manhattan_distance(emb1, emb2)
            
            print(f"{text1} vs {text2:<12} {cosine:.4f}   {euclidean:.2f}     {manhattan:.2f}")
    
    def find_most_similar_texts(self, query: str, candidates: List[str], top_k: int = 3):
        """æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬"""
        print("\nğŸ¯ ç¬¬3éƒ¨åˆ†ï¼šæŸ¥æ‰¾æœ€ç›¸ä¼¼æ–‡æœ¬")
        print("=" * 50)
        
        # è·å–æŸ¥è¯¢åµŒå…¥
        query_embedding = self.get_embedding(query)
        if not query_embedding:
            return []
        
        # æ‰¹é‡è·å–å€™é€‰æ–‡æœ¬åµŒå…¥
        candidate_embeddings = self.get_embeddings_batch(candidates)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for candidate, embedding in zip(candidates, candidate_embeddings):
            sim = self.cosine_similarity(query_embedding, embedding)
            similarities.append((candidate, sim))
        
        # æ’åºå¹¶è¿”å›å‰kä¸ª
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_similar = similarities[:top_k]
        
        print(f"ğŸ” æŸ¥è¯¢: '{query}'")
        print(f"ğŸ“Š æœ€ç›¸ä¼¼çš„{top_k}ä¸ªæ–‡æœ¬:")
        
        for i, (text, sim) in enumerate(top_similar, 1):
            print(f"   {i}. '{text}' (ç›¸ä¼¼åº¦: {sim:.4f})")
        
        return top_similar
    
    def demonstrate_similarity_threshold(self):
        """æ¼”ç¤ºç›¸ä¼¼åº¦é˜ˆå€¼çš„åº”ç”¨"""
        print("\nğŸ¯ ç¬¬4éƒ¨åˆ†ï¼šç›¸ä¼¼åº¦é˜ˆå€¼åº”ç”¨")
        print("=" * 50)
        
        # ç¤ºä¾‹æ–‡æœ¬
        documents = [
            "äººå·¥æ™ºèƒ½æŠ€æœ¯",
            "æœºå™¨å­¦ä¹ ç®—æ³•",
            "æ·±åº¦å­¦ä¹ æ¡†æ¶",
            "è‹¹æœå…¬å¸çš„iPhone",
            "é¦™è•‰çš„è¥å…»ä»·å€¼",
            "æ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡æ•°æ®",
            "æœºå™¨å­¦ä¹ æ˜¯AIçš„å­é›†"
        ]
        
        query = "äººå·¥æ™ºèƒ½"
        
        # è·å–åµŒå…¥
        query_embedding = self.get_embedding(query)
        doc_embeddings = self.get_embeddings_batch(documents)
        
        # ä¸åŒé˜ˆå€¼ä¸‹çš„ç»“æœ
        thresholds = [0.5, 0.7, 0.8, 0.9]
        
        for threshold in thresholds:
            similar_docs = []
            for doc, emb in zip(documents, doc_embeddings):
                sim = self.cosine_similarity(query_embedding, emb)
                if sim >= threshold:
                    similar_docs.append((doc, sim))
            
            similar_docs.sort(key=lambda x: x[1], reverse=True)
            
            print(f"\nğŸ“Š é˜ˆå€¼ {threshold} çš„ç»“æœ:")
            print(f"   åŒ¹é…æ•°é‡: {len(similar_docs)}")
            for doc, sim in similar_docs:
                print(f"   - '{doc}' ({sim:.3f})")
    
    def create_similarity_matrix(self, texts: List[str]):
        """åˆ›å»ºç›¸ä¼¼åº¦çŸ©é˜µ"""
        print("\nğŸ¯ ç¬¬5éƒ¨åˆ†ï¼šç›¸ä¼¼åº¦çŸ©é˜µ")
        print("=" * 50)
        
        # è·å–æ‰€æœ‰æ–‡æœ¬çš„åµŒå…¥
        embeddings = self.get_embeddings_batch(texts)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        n = len(texts)
        similarity_matrix = np.zeros((n, n))
        
        for i in range(n):
            for j in range(n):
                similarity_matrix[i][j] = self.cosine_similarity(embeddings[i], embeddings[j])
        
        # æ‰“å°çŸ©é˜µ
        print("ğŸ“Š ç›¸ä¼¼åº¦çŸ©é˜µ:")
        print("æ–‡æœ¬:", texts)
        print("\nçŸ©é˜µ:")
        print(similarity_matrix)
        
        # ä¿å­˜çŸ©é˜µåˆ°æ–‡ä»¶
        np.savetxt('01-basics/similarity_matrix.txt', similarity_matrix, fmt='%.4f')
        print("\nâœ… ç›¸ä¼¼åº¦çŸ©é˜µå·²ä¿å­˜åˆ° 'similarity_matrix.txt'")
        
        return similarity_matrix

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç¬¬3è¯¾ï¼šè®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦")
    print("=" * 60)
    print("æœ¬è¯¾ç¨‹å°†æ•™ä½ å¦‚ä½•è®¡ç®—æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚\n")
    
    try:
        # åˆ›å»ºè®¡ç®—å™¨å®ä¾‹
        calculator = SimilarityCalculator()
        
        input("ğŸ“Š æŒ‰å›è½¦é”®å¼€å§‹åŸºç¡€ç›¸ä¼¼åº¦è®¡ç®—...")
        print("\n" + "="*60)
        calculator.demonstrate_similarity_calculation()
        
        input("\nğŸ” æŒ‰å›è½¦é”®æ¯”è¾ƒä¸åŒç›¸ä¼¼åº¦æ–¹æ³•...")
        print("\n" + "="*60)
        calculator.compare_different_similarity_methods()
        
        # æŸ¥æ‰¾ç›¸ä¼¼æ–‡æœ¬
        sample_texts = [
            "äººå·¥æ™ºèƒ½æŠ€æœ¯",
            "æœºå™¨å­¦ä¹ ç®—æ³•",
            "æ·±åº¦å­¦ä¹ æ¡†æ¶",
            "è‡ªç„¶è¯­è¨€å¤„ç†",
            "è®¡ç®—æœºè§†è§‰",
            "æ•°æ®ç§‘å­¦",
            "ç¥ç»ç½‘ç»œ",
            "Pythonç¼–ç¨‹",
            "Javaå¼€å‘",
            "Webå¼€å‘"
        ]
        
        input(f"\nğŸ” æŒ‰å›è½¦é”®æŸ¥æ‰¾æœ€ç›¸ä¼¼æ–‡æœ¬ (æŸ¥è¯¢: 'äººå·¥æ™ºèƒ½')...")
        print("\n" + "="*60)
        calculator.find_most_similar_texts("äººå·¥æ™ºèƒ½", sample_texts, top_k=5)
        
        input("\nğŸ“ æŒ‰å›è½¦é”®å­¦ä¹ ç›¸ä¼¼åº¦é˜ˆå€¼åº”ç”¨...")
        print("\n" + "="*60)
        calculator.demonstrate_similarity_threshold()
        
        input("\nğŸ“ˆ æŒ‰å›è½¦é”®åˆ›å»ºç›¸ä¼¼åº¦çŸ©é˜µ...")
        print("\n" + "="*60)
        calculator.create_similarity_matrix(sample_texts[:5])
        
        print("\n" + "="*60)
        print("ğŸ‰ ç¬¬3è¯¾å®Œæˆï¼")
        print("ä½ å·²ç»å­¦ä¼šäº†ï¼š")
        print("âœ… ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—")
        print("âœ… ä¸åŒç›¸ä¼¼åº¦æ–¹æ³•æ¯”è¾ƒ")
        print("âœ… æŸ¥æ‰¾æœ€ç›¸ä¼¼æ–‡æœ¬")
        print("âœ… ä½¿ç”¨ç›¸ä¼¼åº¦é˜ˆå€¼")
        print("âœ… åˆ›å»ºç›¸ä¼¼åº¦çŸ©é˜µ")
        print("\nğŸ“‚ ç›¸ä¼¼åº¦çŸ©é˜µå·²ä¿å­˜åˆ° 'similarity_matrix.txt'")
        print("\nğŸ¯ ä¸‹ä¸€è¯¾ï¼š04-vector-operations.py - å‘é‡æ“ä½œåŸºç¡€")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ è¯¾ç¨‹å·²ä¸­æ–­ï¼Œæ¬¢è¿ä¸‹æ¬¡ç»§ç»­å­¦ä¹ ï¼")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        print("ğŸ”„ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®åé‡è¯•")
    finally:
        input("\nğŸ“š æŒ‰å›è½¦é”®é€€å‡ºè¯¾ç¨‹...")

if __name__ == "__main__":
    main()