#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­çº§è¯¾ç¨‹ç¬¬3è¯¾ï¼šæ–‡æœ¬æ¨èç³»ç»Ÿ
=======================

åŸºäºå®˜æ–¹ç¤ºä¾‹çš„æ–‡æœ¬æ¨èç³»ç»Ÿå®ç°ã€‚
é€šè¿‡æ–‡æœ¬åµŒå…¥å®ç°æ–‡ç« æ ‡é¢˜çš„ä¸ªæ€§åŒ–æ¨èã€‚

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£æ¨èç³»ç»Ÿçš„å·¥ä½œåŸç†
2. æŒæ¡ç¼“å­˜æœºåˆ¶çš„ä½¿ç”¨
3. å®ç°åŸºäºå†…å®¹çš„æ¨è
4. ä¼˜åŒ–æ¨èç®—æ³•æ€§èƒ½
5. å¤„ç†å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®
"""

import os
import sys
import pickle
import numpy as np
from typing import List, Dict, Tuple
import pandas as pd

# æ·»åŠ utilsç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.embedding_client import EmbeddingClient

class TextRecommendationSystem:
    """æ–‡æœ¬æ¨èç³»ç»Ÿ"""
    
    def __init__(self, cache_file: str = "text_recommendations.pkl"):
        """åˆå§‹åŒ–æ¨èç³»ç»Ÿ"""
        self.client = EmbeddingClient()
        self.cache_file = cache_file
        self.embedding_cache = {}
        self.texts = []
        
    def load_sample_data(self) -> List[str]:
        """åŠ è½½ç¤ºä¾‹æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ–°é—»æ ‡é¢˜ï¼‰"""
        sample_titles = [
            "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—é¢†åŸŸçš„çªç ´æ€§åº”ç”¨",
            "æœºå™¨å­¦ä¹ ç®—æ³•ä¼˜åŒ–æå‡æœç´¢å¼•æ“å‡†ç¡®æ€§",
            "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­çš„æœ€æ–°è¿›å±•",
            "Pythonæ•°æ®ç§‘å­¦åº“çš„æ–°ç‰ˆæœ¬å‘å¸ƒ",
            "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æ”¹å˜å®¢æˆ·æœåŠ¡ä½“éªŒ",
            "åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èè¡Œä¸šçš„åˆ›æ–°åº”ç”¨",
            "äº‘è®¡ç®—æœåŠ¡é™ä½ä¼ä¸šITæˆæœ¬",
            "å¤§æ•°æ®åˆ†ææ–¹æ³•åŠ©åŠ›ç²¾å‡†è¥é”€",
            "ç‰©è”ç½‘æŠ€æœ¯æ¨åŠ¨æ™ºèƒ½å®¶å±…å‘å±•",
            "é‡å­è®¡ç®—ç ”ç©¶å–å¾—é‡è¦çªç ´",
            "5Gç½‘ç»œæŠ€æœ¯æ”¹å˜é€šä¿¡è¡Œä¸šæ ¼å±€",
            "è™šæ‹Ÿç°å®æŠ€æœ¯åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨",
            "è‡ªåŠ¨é©¾é©¶æŠ€æœ¯é¢ä¸´çš„å®‰å…¨æŒ‘æˆ˜",
            "æ–°èƒ½æºæŠ€æœ¯æ¨åŠ¨å¯æŒç»­å‘å±•",
            "ç½‘ç»œå®‰å…¨æŠ€æœ¯åº”å¯¹æ–°å‹å¨èƒ"
        ]
        return sample_titles
    
    def get_embedding_with_cache(self, text: str) -> List[float]:
        """è·å–åµŒå…¥å‘é‡å¹¶ç¼“å­˜"""
        if text not in self.embedding_cache:
            embedding = self.client.get_embedding(text)
            if embedding:
                self.embedding_cache[text] = embedding
        return self.embedding_cache.get(text, [])
    
    def save_cache(self):
        """ä¿å­˜åµŒå…¥ç¼“å­˜"""
        try:
            with open(self.cache_file, 'wb') as f:
                pickle.dump(self.embedding_cache, f)
            print(f"âœ… ç¼“å­˜å·²ä¿å­˜ï¼š{len(self.embedding_cache)}ä¸ªåµŒå…¥")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥ï¼š{e}")
    
    def load_cache(self) -> bool:
        """åŠ è½½åµŒå…¥ç¼“å­˜"""
        try:
            with open(self.cache_file, 'rb') as f:
                self.embedding_cache = pickle.load(f)
            print(f"âœ… ç¼“å­˜å·²åŠ è½½ï¼š{len(self.embedding_cache)}ä¸ªåµŒå…¥")
            return True
        except FileNotFoundError:
            print("ğŸ†• æœªæ‰¾åˆ°ç¼“å­˜æ–‡ä»¶")
            return False
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not vec1 or not vec2:
            return 0.0
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    
    def setup_system(self, texts: List[str]) -> bool:
        """è®¾ç½®æ¨èç³»ç»Ÿ"""
        self.texts = texts
        
        # å°è¯•åŠ è½½ç¼“å­˜
        cache_loaded = self.load_cache()
        
        # æ£€æŸ¥éœ€è¦å¤„ç†çš„æ–‡æœ¬
        texts_to_process = [t for t in texts if t not in self.embedding_cache]
        
        if texts_to_process:
            print(f"ğŸ”„ æ­£åœ¨å¤„ç†{len(texts_to_process)}ä¸ªæ–°æ–‡æœ¬...")
            embeddings = self.client.get_embeddings_batch(texts_to_process)
            
            for text, embedding in zip(texts_to_process, embeddings):
                if embedding:
                    self.embedding_cache[text] = embedding
            
            self.save_cache()
        
        return True
    
    def get_recommendations(self, query_text: str, k: int = 3) -> List[Dict]:
        """è·å–æ–‡æœ¬æ¨è"""
        if not self.texts:
            return []
        
        # è·å–æŸ¥è¯¢æ–‡æœ¬çš„åµŒå…¥
        query_embedding = self.get_embedding_with_cache(query_text)
        if not query_embedding:
            return []
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for text in self.texts:
            text_embedding = self.get_embedding_with_cache(text)
            if text_embedding:
                similarity = self.cosine_similarity(query_embedding, text_embedding)
                similarities.append((text, similarity))
        
        # æ’åºå¹¶è¿”å›å‰kä¸ª
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_results = similarities[:k]
        
        return [
            {"text": text, "similarity": score}
            for text, score in top_results
        ]
    
    def recommend_similar_articles(self, index: int, k: int = 3) -> List[Dict]:
        """æ¨èç›¸ä¼¼æ–‡ç« """
        if index < 0 or index >= len(self.texts):
            return []
        
        source_text = self.texts[index]
        source_embedding = self.get_embedding_with_cache(source_text)
        
        if not source_embedding:
            return []
        
        similarities = []
        for i, text in enumerate(self.texts):
            if i == index:
                continue
            
            text_embedding = self.get_embedding_with_cache(text)
            if text_embedding:
                similarity = self.cosine_similarity(source_embedding, text_embedding)
                similarities.append((text, similarity, i))
        
        # æ’åºå¹¶è¿”å›å‰kä¸ª
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_results = similarities[:k]
        
        return [
            {"text": text, "similarity": score, "index": idx}
            for text, score, idx in top_results
        ]
    
    def get_similarity_matrix(self) -> np.ndarray:
        """è·å–ç›¸ä¼¼åº¦çŸ©é˜µ"""
        if not self.texts:
            return np.array([])
        
        n = len(self.texts)
        matrix = np.zeros((n, n))
        
        embeddings = [self.get_embedding_with_cache(text) for text in self.texts]
        
        for i in range(n):
            for j in range(n):
                if embeddings[i] and embeddings[j]:
                    matrix[i][j] = self.cosine_similarity(embeddings[i], embeddings[j])
        
        return matrix
    
    def demo_recommendation_system(self):
        """æ¼”ç¤ºæ¨èç³»ç»Ÿ"""
        print("ğŸ¯ æ–‡æœ¬æ¨èç³»ç»Ÿæ¼”ç¤º")
        print("=" * 40)
        
        # åŠ è½½ç¤ºä¾‹æ•°æ®
        texts = self.load_sample_data()
        print(f"ğŸ“Š å·²åŠ è½½{len(texts)}ä¸ªæ–‡æœ¬")
        
        # è®¾ç½®ç³»ç»Ÿ
        self.setup_system(texts)
        
        # æ¼”ç¤ºæ¨èåŠŸèƒ½
        print("\nğŸ” åŸºäºæ–‡æœ¬çš„æ¨èæ¼”ç¤ºï¼š")
        
        test_queries = [
            "äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿",
            "ç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶",
            "ç½‘ç»œå®‰å…¨å’Œæ•°æ®ä¿æŠ¤",
            "æ–°èƒ½æºæŠ€æœ¯åº”ç”¨"
        ]
        
        for query in test_queries:
            print(f"\nğŸ“ æŸ¥è¯¢ï¼š'{query}'")
            recommendations = self.get_recommendations(query, k=2)
            
            for rec in recommendations:
                print(f"   ğŸ“„ {rec['text'][:50]}... (ç›¸ä¼¼åº¦ï¼š{rec['similarity']:.3f})")
        
        # æ¼”ç¤ºç›¸ä¼¼æ–‡ç« æ¨è
        print("\nğŸ”— ç›¸ä¼¼æ–‡ç« æ¨èæ¼”ç¤ºï¼š")
        
        for idx in [0, 5, 10]:  # é€‰æ‹©å‡ ä¸ªä¸åŒçš„æ–‡ç« 
            if idx < len(texts):
                print(f"\nåŸºäºç¬¬{idx+1}ç¯‡æ–‡ç« ï¼š{texts[idx][:30]}...")
                similar = self.recommend_similar_articles(idx, k=2)
                
                for rec in similar:
                    print(f"   ğŸ“„ {rec['text'][:50]}... (ç›¸ä¼¼åº¦ï¼š{rec['similarity']:.3f})")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¸­çº§è¯¾ç¨‹ç¬¬3è¯¾ï¼šæ–‡æœ¬æ¨èç³»ç»Ÿ")
    print("=" * 60)
    print("é€šè¿‡æ–‡æœ¬åµŒå…¥å®ç°æ–‡ç« æ ‡é¢˜çš„ä¸ªæ€§åŒ–æ¨èã€‚\n")
    
    try:
        # æ£€æŸ¥APIå¯†é’¥
        if not os.getenv("DASHSCOPE_API_KEY"):
            print("ğŸ”‘ APIå¯†é’¥æ£€æŸ¥")
            print("-" * 30)
            print("âš ï¸ æœªæ£€æµ‹åˆ° DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
            print("\nè§£å†³æ–¹æ³•ï¼š")
            print("1. ä¸´æ—¶è®¾ç½®: set DASHSCOPE_API_KEY=ä½ çš„å¯†é’¥ (Windows)")
            print("2. ä¸´æ—¶è®¾ç½®: export DASHSCOPE_API_KEY=ä½ çš„å¯†é’¥ (Linux/Mac)")
            print("\nğŸ“ è·å–APIå¯†é’¥ï¼š")
            print("   è®¿é—® https://dashscope.console.aliyun.com ç”³è¯·")
            return
        else:
            print("âœ… æ£€æµ‹åˆ°APIå¯†é’¥")
        
        input("\nğŸ“° æŒ‰å›è½¦é”®å¼€å§‹æ¨èç³»ç»Ÿæ¼”ç¤º...")
        print("\n" + "="*60)
        system = TextRecommendationSystem()
        system.demo_recommendation_system()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ¨èç³»ç»Ÿè¯¾ç¨‹å®Œæˆï¼")
        print("ğŸ¯ ä½ å·²ç»æŒæ¡äº†ï¼š")
        print("âœ… åŸºäºå†…å®¹çš„æ¨è")
        print("âœ… ç›¸ä¼¼åº¦è®¡ç®—")
        print("âœ… ç¼“å­˜æœºåˆ¶ä¼˜åŒ–")
        print("âœ… å¤§è§„æ¨¡æ•°æ®å¤„ç†")
        print("\nğŸš€ å®é™…åº”ç”¨åœºæ™¯:")
        print("   â€¢ æ–‡ç« æ¨èç³»ç»Ÿ")
        print("   â€¢ äº§å“æ¨èå¼•æ“")
        print("   â€¢ ä¸ªæ€§åŒ–å†…å®¹æ¨è")
        print("   â€¢ ç”¨æˆ·å…´è¶£å»ºæ¨¡")
        print("\nğŸ“‚ ç¼“å­˜æ–‡ä»¶å·²ä¿å­˜ä¸º 'text_recommendations.pkl'")
        print("\nğŸ¯ å‡†å¤‡è¿›å…¥ä¸‹ä¸€è¯¾ç¨‹...")
        print("\nä¸­çº§æ¨¡å—ï¼š04-clustering-analysis.py - èšç±»åˆ†æ")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ è¯¾ç¨‹å·²ä¸­æ–­ï¼Œæ¬¢è¿ä¸‹æ¬¡ç»§ç»­å­¦ä¹ ï¼")
    except Exception as e:
        print(f"\nâŒ è¿è¡Œé”™è¯¯ï¼š{e}")
        print("ğŸ”„ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®")
    finally:
        input("\nğŸ“š æŒ‰å›è½¦é”®é€€å‡ºè¯¾ç¨‹...")

if __name__ == "__main__":
    main()