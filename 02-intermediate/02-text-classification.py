#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­çº§è¯¾ç¨‹ç¬¬2è¯¾ï¼šæ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ
=======================

åŸºäºæ–‡æœ¬åµŒå…¥çš„æ–‡æœ¬è‡ªåŠ¨åˆ†ç±»ç³»ç»Ÿå®ç°ã€‚
é€šè¿‡å‘é‡åŒ–æŠ€æœ¯å®ç°æ–°é—»ã€è¯„è®ºã€é‚®ä»¶ç­‰æ–‡æœ¬çš„è‡ªåŠ¨åˆ†ç±»ã€‚

å­¦ä¹ ç›®æ ‡ï¼š
1. ç†è§£æ–‡æœ¬åˆ†ç±»çš„å·¥ä½œåŸç†
2. æŒæ¡åŸºäºåµŒå…¥çš„åˆ†ç±»æ–¹æ³•
3. å®ç°é›¶æ ·æœ¬åˆ†ç±»
4. å¤šæ ‡ç­¾åˆ†ç±»å®ç°
5. ç½®ä¿¡åº¦è¯„ä¼°å’Œé˜ˆå€¼è®¾ç½®
"""

import os
import sys
import numpy as np
from typing import List, Dict, Tuple
import pandas as pd

# æ·»åŠ utilsç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.embedding_client import EmbeddingClient

class TextClassificationSystem:
    """æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†ç±»ç³»ç»Ÿ"""
        self.client = EmbeddingClient()
        self.category_embeddings = {}
        self.training_data = {}
        
    def load_sample_data(self) -> Dict[str, List[str]]:
        """åŠ è½½ç¤ºä¾‹åˆ†ç±»æ•°æ®"""
        sample_data = {
            "ç§‘æŠ€": [
                "äººå·¥æ™ºèƒ½æŠ€æœ¯å–å¾—é‡å¤§çªç ´ï¼Œæ·±åº¦å­¦ä¹ ç®—æ³•æ€§èƒ½æå‡æ˜¾è‘—",
                "è‹¹æœå…¬å¸å‘å¸ƒæ–°ä¸€ä»£èŠ¯ç‰‡ï¼Œè®¡ç®—èƒ½åŠ›æå‡50%",
                "é‡å­è®¡ç®—æœºç ”ç©¶è·å¾—æ–°è¿›å±•ï¼Œæœ‰æœ›è§£å†³å¤æ‚é—®é¢˜",
                "5Gç½‘ç»œæŠ€æœ¯æ¨åŠ¨ç‰©è”ç½‘åº”ç”¨å¿«é€Ÿå‘å±•"
            ],
            "ä½“è‚²": [
                "å›½è¶³åœ¨ä¸–ç•Œæ¯é¢„é€‰èµ›ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ™‹çº§ä¸‹ä¸€è½®",
                "NBAæ€»å†³èµ›å³å°†æ‰“å“ï¼Œæ¹–äººé˜Ÿå’Œå‡¯å°”ç‰¹äººé˜Ÿäº‰å¤ºå† å†›",
                "ä¸­å›½å¥³æ’åœ¨ä¸–ç•Œé”¦æ ‡èµ›ä¸­è·å¾—é‡‘ç‰Œï¼Œå±•ç°å¼ºå¤§å®åŠ›",
                "è¶³çƒä¸–ç•Œæ¯å³å°†å¼€å¹•ï¼Œå„æ”¯çƒé˜Ÿç§¯æå¤‡æˆ˜"
            ],
            "è´¢ç»": [
                "å¤®è¡Œå®£å¸ƒé™æ¯æ”¿ç­–ï¼Œåˆºæ¿€ç»æµå¢é•¿",
                "è‚¡ç¥¨å¸‚åœºä»Šæ—¥å¤§æ¶¨ï¼Œç§‘æŠ€è‚¡é¢†æ¶¨å¤§ç›˜",
                "æˆ¿åœ°äº§å¸‚åœºè°ƒæ§æ”¿ç­–æ•ˆæœæ˜¾è‘—ï¼Œæˆ¿ä»·è¶‹äºç¨³å®š",
                "å›½é™…è´¸æ˜“åˆä½œåŠ å¼ºï¼ŒåŒè¾¹è´¸æ˜“é¢åˆ›æ–°é«˜"
            ],
            "å¨±ä¹": [
                "ç”µå½±ã€Šæµæµªåœ°çƒ3ã€‹ç¥¨æˆ¿çªç ´10äº¿ï¼Œåˆ›å½±å²çºªå½•",
                "æŸçŸ¥åæ­Œæ‰‹å‘å¸ƒæ–°ä¸“è¾‘ï¼ŒéŸ³ä¹é£æ ¼å¤§å—å¥½è¯„",
                "ç”µè§†å‰§ã€Šä¸‰ä½“ã€‹è·å¾—è§‚ä¼—ä¸€è‡´å¥½è¯„ï¼Œç§‘å¹»é¢˜æå—æ¬¢è¿",
                "ç»¼è‰ºèŠ‚ç›®åˆ›æ–°å½¢å¼ï¼Œå¸å¼•å¤§é‡å¹´è½»è§‚ä¼—"
            ]
        }
        return sample_data
    
    def prepare_category_embeddings(self, categories: Dict[str, List[str]]):
        """å‡†å¤‡ç±»åˆ«åµŒå…¥å‘é‡"""
        print("ğŸ¯ å‡†å¤‡ç±»åˆ«åµŒå…¥...")
        
        for category, examples in categories.items():
            # è·å–ç±»åˆ«åç§°çš„åµŒå…¥
            category_embedding = self.client.get_embedding(category)
            
            # è·å–ç¤ºä¾‹æ–‡æœ¬çš„å¹³å‡åµŒå…¥
            example_embeddings = []
            for example in examples:
                embedding = self.client.get_embedding(example)
                example_embeddings.append(embedding)
            
            # è®¡ç®—ç±»åˆ«ä¸­å¿ƒå‘é‡
            category_center = np.mean(example_embeddings, axis=0)
            
            self.category_embeddings[category] = {
                'name': category,
                'embedding': category_center,
                'examples': examples
            }
            print(f"   âœ… {category} ç±»åˆ«å·²å‡†å¤‡å®Œæˆ")
    
    def classify_text(self, text: str, threshold: float = 0.6) -> List[Dict[str, float]]:
        """å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»"""
        if not self.category_embeddings:
            raise ValueError("è¯·å…ˆè°ƒç”¨prepare_category_embeddings()å‡†å¤‡ç±»åˆ«æ•°æ®")
        
        # è·å–æ–‡æœ¬åµŒå…¥
        text_embedding = np.array(self.client.get_embedding(text))
        
        # è®¡ç®—ä¸æ¯ä¸ªç±»åˆ«çš„ç›¸ä¼¼åº¦
        similarities = []
        for category_name, category_data in self.category_embeddings.items():
            category_embedding = np.array(category_data['embedding'])
            similarity = np.dot(text_embedding, category_embedding) / (
                np.linalg.norm(text_embedding) * np.linalg.norm(category_embedding)
            )
            similarities.append({
                'category': category_name,
                'similarity': similarity,
                'confidence': similarity
            })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„åˆ†ç±»
        filtered_results = [result for result in similarities if result['similarity'] >= threshold]
        
        return filtered_results
    
    def zero_shot_classification(self, text: str, candidate_labels: List[str]) -> Dict[str, float]:
        """é›¶æ ·æœ¬åˆ†ç±»"""
        print(f"\nğŸ¯ é›¶æ ·æœ¬åˆ†ç±»: '{text[:30]}...'")
        
        # è·å–æ–‡æœ¬åµŒå…¥
        text_embedding = np.array(self.client.get_embedding(text))
        
        # è®¡ç®—ä¸æ¯ä¸ªå€™é€‰æ ‡ç­¾çš„ç›¸ä¼¼åº¦
        label_similarities = {}
        for label in candidate_labels:
            label_embedding = np.array(self.client.get_embedding(label))
            similarity = np.dot(text_embedding, label_embedding) / (
                np.linalg.norm(text_embedding) * np.linalg.norm(label_embedding)
            )
            label_similarities[label] = similarity
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        sorted_labels = sorted(label_similarities.items(), key=lambda x: x[1], reverse=True)
        
        return dict(sorted_labels)
    
    def multi_label_classification(self, text: str, labels: List[str], threshold: float = 0.5) -> List[str]:
        """å¤šæ ‡ç­¾åˆ†ç±»"""
        print(f"\nğŸ·ï¸ å¤šæ ‡ç­¾åˆ†ç±»: '{text[:30]}...'")
        
        # è·å–æ‰€æœ‰æ ‡ç­¾çš„ç›¸ä¼¼åº¦
        similarities = self.zero_shot_classification(text, labels)
        
        # è¿”å›è¶…è¿‡é˜ˆå€¼çš„æ ‡ç­¾
        applicable_labels = [label for label, score in similarities.items() if score >= threshold]
        
        return applicable_labels
    
    def evaluate_classification_accuracy(self, test_data: Dict[str, List[str]]) -> Dict[str, float]:
        """è¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡"""
        print("\nğŸ“Š è¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡...")
        
        correct_predictions = 0
        total_predictions = 0
        category_stats = {}
        
        for true_category, test_texts in test_data.items():
            category_stats[true_category] = {'correct': 0, 'total': 0}
            
            for test_text in test_texts:
                # åˆ†ç±»æ–‡æœ¬
                predictions = self.classify_text(test_text, threshold=0.3)
                
                if predictions:
                    predicted_category = predictions[0]['category']
                    
                    if predicted_category == true_category:
                        correct_predictions += 1
                        category_stats[true_category]['correct'] += 1
                    
                    total_predictions += 1
                    category_stats[true_category]['total'] += 1
        
        # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
        overall_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
        
        # è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡
        category_accuracies = {}
        for category, stats in category_stats.items():
            if stats['total'] > 0:
                category_accuracies[category] = stats['correct'] / stats['total']
        
        return {
            'overall_accuracy': overall_accuracy,
            'category_accuracies': category_accuracies,
            'category_stats': category_stats
        }
    
    def demonstrate_confidence_thresholding(self):
        """æ¼”ç¤ºç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®"""
        print("\nğŸ¯ ç¬¬3éƒ¨åˆ†ï¼šç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®")
        print("=" * 50)
        
        test_texts = [
            "è‹¹æœå…¬å¸å‘å¸ƒæ–°ä¸€ä»£iPhoneï¼Œæ­è½½æœ€æ–°èŠ¯ç‰‡æŠ€æœ¯",
            "å›½è¶³åœ¨äºšæ´²æ¯æ¯”èµ›ä¸­è¡¨ç°å‡ºè‰²ï¼Œçƒè¿·çƒ­æƒ…é«˜æ¶¨",
            "å¤®è¡Œå®£å¸ƒæ–°çš„è´§å¸æ”¿ç­–ï¼Œå½±å“è‚¡å¸‚å’Œæˆ¿åœ°äº§å¸‚åœº",
            "æŸçŸ¥åæ¼”å‘˜å‘å¸ƒæ–°æ­Œï¼ŒéŸ³ä¹é£æ ¼åˆ›æ–°ç‹¬ç‰¹"
        ]
        
        thresholds = [0.3, 0.5, 0.7, 0.9]
        
        for text in test_texts:
            print(f"\nğŸ“„ æµ‹è¯•æ–‡æœ¬: {text}")
            for threshold in thresholds:
                results = self.classify_text(text, threshold=threshold)
                if results:
                    category = results[0]['category']
                    confidence = results[0]['confidence']
                    print(f"   é˜ˆå€¼ {threshold}: {category} (ç½®ä¿¡åº¦: {confidence:.3f})")
                else:
                    print(f"   é˜ˆå€¼ {threshold}: æ— åŒ¹é…ç±»åˆ«")
    
    def demo_text_classification(self):
        """æ¼”ç¤ºæ–‡æœ¬åˆ†ç±»åŠŸèƒ½"""
        print("ğŸš€ æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿæ¼”ç¤º")
        print("=" * 60)
        
        # åŠ è½½ç¤ºä¾‹æ•°æ®
        sample_data = self.load_sample_data()
        
        # å‡†å¤‡ç±»åˆ«åµŒå…¥
        self.prepare_category_embeddings(sample_data)
        
        # æ¼”ç¤ºåˆ†ç±»åŠŸèƒ½
        test_texts = [
            "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨æ”¹å˜åŒ»ç–—è¡Œä¸šçš„è¯Šæ–­æ–¹å¼",
            "è¶³çƒé˜Ÿåœ¨ä¸–ç•Œæ¯é¢„é€‰èµ›ä¸­è·å¾—é‡è¦èƒœåˆ©",
            "å¤®è¡Œå®£å¸ƒæ–°çš„é‡‘èæ”¿ç­–ï¼Œåˆºæ¿€ç»æµå¢é•¿",
            "æ–°ç”µå½±ç¥¨æˆ¿çªç ´è®°å½•ï¼Œè§‚ä¼—åå“çƒ­çƒˆ"
        ]
        
        print("\nğŸ¯ ç¬¬1éƒ¨åˆ†ï¼šæ–‡æœ¬åˆ†ç±»æ¼”ç¤º")
        print("=" * 50)
        
        for text in test_texts:
            print(f"\nğŸ“„ æ–‡æœ¬: {text}")
            results = self.classify_text(text, threshold=0.5)
            
            if results:
                print(f"   ğŸ·ï¸ åˆ†ç±»ç»“æœ:")
                for result in results[:3]:  # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
                    print(f"      {result['category']}: {result['confidence']:.3f}")
            else:
                print("   âŒ æ— æ³•åˆ†ç±»")
        
        # æ¼”ç¤ºé›¶æ ·æœ¬åˆ†ç±»
        print("\nğŸ¯ ç¬¬2éƒ¨åˆ†ï¼šé›¶æ ·æœ¬åˆ†ç±»æ¼”ç¤º")
        print("=" * 50)
        
        zero_shot_text = "æŸç§‘æŠ€å…¬å¸å®£å¸ƒå¼€å‘æ–°å‹é‡å­è®¡ç®—èŠ¯ç‰‡"
        candidate_labels = ["ç§‘æŠ€", "ä½“è‚²", "è´¢ç»", "å¨±ä¹", "æ•™è‚²", "åŒ»ç–—"]
        
        zero_shot_results = self.zero_shot_classification(zero_shot_text, candidate_labels)
        print(f"\nğŸ“„ æ–‡æœ¬: {zero_shot_text}")
        print("ğŸ” é›¶æ ·æœ¬åˆ†ç±»ç»“æœ:")
        for label, score in list(zero_shot_results.items())[:3]:
            print(f"   {label}: {score:.3f}")
        
        # æ¼”ç¤ºå¤šæ ‡ç­¾åˆ†ç±»
        print("\nğŸ¯ ç¬¬3éƒ¨åˆ†ï¼šå¤šæ ‡ç­¾åˆ†ç±»æ¼”ç¤º")
        print("=" * 50)
        
        multi_label_text = "äººå·¥æ™ºèƒ½æŠ€æœ¯åº”ç”¨äºåŒ»ç–—è¯Šæ–­ï¼Œæé«˜ç–¾ç—…æ£€æµ‹å‡†ç¡®ç‡"
        multi_labels = ["ç§‘æŠ€", "åŒ»ç–—", "æ•™è‚²", "å•†ä¸š", "ç ”ç©¶"]
        
        multi_results = self.multi_label_classification(multi_label_text, multi_labels)
        print(f"\nğŸ“„ æ–‡æœ¬: {multi_label_text}")
        print("ğŸ·ï¸ å¤šæ ‡ç­¾åˆ†ç±»ç»“æœ:")
        for label in multi_results:
            print(f"   âœ… {label}")
        
        # æ¼”ç¤ºç½®ä¿¡åº¦é˜ˆå€¼
        self.demonstrate_confidence_thresholding()
        
        # è¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡
        print("\nğŸ¯ ç¬¬4éƒ¨åˆ†ï¼šåˆ†ç±»å‡†ç¡®ç‡è¯„ä¼°")
        print("=" * 50)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            "ç§‘æŠ€": [
                "æ–°å‹äººå·¥æ™ºèƒ½æŠ€æœ¯çªç ´ä¼ ç»Ÿç®—æ³•é™åˆ¶",
                "5Gç½‘ç»œæŠ€æœ¯æ¨åŠ¨ç‰©è”ç½‘å¿«é€Ÿå‘å±•",
                "é‡å­è®¡ç®—æœºç ”ç©¶å–å¾—é‡è¦è¿›å±•"
            ],
            "ä½“è‚²": [
                "ä¸–ç•Œæ¯è¶³çƒèµ›å³å°†å¼€å¹•ï¼Œå„é˜Ÿç§¯æå¤‡æˆ˜",
                "NBAå­£åèµ›ç«äº‰æ¿€çƒˆï¼Œå¤šæ”¯çƒé˜Ÿæœ‰æœ›å¤ºå† ",
                "å¥¥è¿ä¼šç­¹å¤‡å·¥ä½œè¿›å±•é¡ºåˆ©ï¼Œåœºé¦†å»ºè®¾å®Œæˆ"
            ],
            "è´¢ç»": [
                "è‚¡å¸‚ä»Šæ—¥å¤§æ¶¨ï¼Œç§‘æŠ€è‚¡é¢†æ¶¨å¸‚åœº",
                "å¤®è¡Œå®£å¸ƒé™æ¯æ”¿ç­–ï¼Œåˆºæ¿€ç»æµå¢é•¿",
                "æˆ¿åœ°äº§å¸‚åœºè°ƒæ§æ”¿ç­–æ•ˆæœæ˜¾è‘—"
            ]
        }
        
        evaluation_results = self.evaluate_classification_accuracy(test_data)
        print(f"æ€»ä½“å‡†ç¡®ç‡: {evaluation_results['overall_accuracy']:.2%}")
        
        for category, accuracy in evaluation_results['category_accuracies'].items():
            print(f"{category}: {accuracy:.2%}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿ")
    print("=" * 60)
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv("DASHSCOPE_API_KEY"):
        print("âš ï¸ è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    try:
        classifier = TextClassificationSystem()
        classifier.demo_text_classification()
        
        print("\nğŸ‰ æ–‡æœ¬åˆ†ç±»æ¼”ç¤ºå®Œæˆï¼")
        print("\næ ¸å¿ƒæŠ€æœ¯æ€»ç»“:")
        print("   â€¢ åŸºäºåµŒå…¥çš„æ–‡æœ¬åˆ†ç±»")
        print("   â€¢ é›¶æ ·æœ¬åˆ†ç±»")
        print("   â€¢ å¤šæ ‡ç­¾åˆ†ç±»")
        print("   â€¢ ç½®ä¿¡åº¦è¯„ä¼°")
        print("\nå®é™…åº”ç”¨åœºæ™¯:")
        print("   â€¢ æ–°é—»æ–‡ç« è‡ªåŠ¨åˆ†ç±»")
        print("   â€¢ åƒåœ¾é‚®ä»¶æ£€æµ‹")
        print("   â€¢ å®¢æˆ·åé¦ˆåˆ†æ")
        print("   â€¢ ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸")
        print("\nä¸‹ä¸€è¯¾ï¼š03-recommendation-system.py - æ¨èç³»ç»Ÿ")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")

if __name__ == "__main__":
    main()